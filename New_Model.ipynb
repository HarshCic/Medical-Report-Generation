{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import csv\n",
    "from os import listdir\n",
    "import keras as K\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, LSTM, GRU, Embedding, TimeDistributed,BatchNormalization, Dense,Dropout, RepeatVector, Activation, Flatten\n",
    "from keras.preprocessing import image, sequence\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.applications import VGG16\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from keras.optimizers import Adam\n",
    "import scipy\n",
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from matplotlib.pyplot import imshow\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.applications.imagenet_utils import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "json1_file = open('captions.json')\n",
    "json1_str = json1_file.read()\n",
    "caption_data = json.loads(json1_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(caption_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"total_string = \"<sss> \" + row[4] + \" . \" + row[5] + \" \" + row[6]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CXR1137_IM-0093-12012.. and ..CXR1137_IM-0093-4004\n",
      "CXR1142_IM-0096-1001.. and ..CXR1142_IM-0096-2001\n",
      "CXR1297_IM-0195-1001.. and ..CXR1297_IM-0195-4004\n",
      "CXR16_IM-0389-1001.. and ..CXR16_IM-0389-2001\n",
      "CXR1690_IM-0452-1001-0001.. and ..CXR1690_IM-0452-1001-0002\n",
      "CXR1778_IM-0509-1001.. and ..CXR1778_IM-0509-2001\n",
      "CXR2115_IM-0744-1001.. and ..CXR2115_IM-0744-2001\n",
      "CXR2765_IM-1210-1001.. and ..CXR2765_IM-1210-2001\n",
      "CXR3367_IM-1619-3001.. and ..CXR3367_IM-1619-4001\n",
      "CXR3376_IM-1625-0001-0001.. and ..CXR3376_IM-1625-0001-0002\n",
      "CXR3434_IM-1662-1001.. and ..CXR3434_IM-1662-2001\n",
      "CXR614_IM-2200-1001.. and ..CXR614_IM-2200-4001\n",
      "CXR894_IM-2404-0001-0001.. and ..CXR894_IM-2404-0001-0002\n"
     ]
    }
   ],
   "source": [
    "all_caption_list = []\n",
    "\n",
    "with open('preprocess.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    count = 0\n",
    "    for row in csv_reader:\n",
    "        if count == 0:\n",
    "            count = count+1\n",
    "            continue\n",
    "        row_insert = []\n",
    "        row_insert.append(row[0])\n",
    "        total_string = \"\"\n",
    "        check = 1\n",
    "        try :\n",
    "            total_string = \"<sss> \" + caption_data[row[1]+\".png\"] + \" <eee>\"\n",
    "        except:\n",
    "            try:\n",
    "                print(row[1] ,end='..', flush=True)\n",
    "                total_string = \"<sss> \" + caption_data[row[2]+\".png\"] + \" <eee>\"\n",
    "            except:\n",
    "                print(\" and ..\" + row[2],end='\\n', flush=True)\n",
    "                check = 0\n",
    "        if check == 1:\n",
    "            row_insert.append(total_string)\n",
    "            all_caption_list.append(row_insert)\n",
    "\n",
    "with open(\"train_caption_final.csv\", \"w\", newline='') as output:\n",
    "    writer = csv.writer(output)\n",
    "    writer.writerows(all_caption_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoded_images = pickle.load( open( \"visual_features.pickle\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#find vocab_size\n",
    "#find total_sample\n",
    "def initialize():\n",
    "        df = pd.read_csv('train_caption_final.csv', delimiter=',')\n",
    "        nb_samples = df.shape[0]\n",
    "        iteration = df.iterrows()\n",
    "        caps = []\n",
    "        for i in range(nb_samples):\n",
    "            x = iteration.__next__()\n",
    "            caps.append(x[1][1])\n",
    "\n",
    "        total_samples=0\n",
    "        for text in caps:\n",
    "            total_samples+=len(text.split())-1\n",
    "        print(\"Total samples : \"+str(total_samples))\n",
    "        \n",
    "        words = [txt.split() for txt in caps]\n",
    "        unique = []\n",
    "        for word in words:\n",
    "            unique.extend(word)\n",
    "        unique = list(set(unique))\n",
    "        vocab_size = len(unique)\n",
    "        word_index = {}\n",
    "        index_word = {}\n",
    "        for i, word in enumerate(unique):\n",
    "            word_index[word]=i\n",
    "            index_word[i]=word\n",
    "\n",
    "        max_len = 0\n",
    "        for caption in caps:\n",
    "            if(len(caption.split()) > max_len):\n",
    "                max_len = len(caption.split())\n",
    "        max_cap_len = max_len\n",
    "        print(\"Vocabulary size: \"+str(vocab_size))\n",
    "        print(\"Maximum caption length: \"+str(max_cap_len))\n",
    "        \n",
    "        return max_cap_len, vocab_size, total_samples, word_index, index_word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples : 120904\n",
      "Vocabulary size: 2556\n",
      "Maximum caption length: 178\n"
     ]
    }
   ],
   "source": [
    "max_capt_len, vocab_size, total_samples, word_to_index, index_to_word = initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state_size = max_capt_len\n",
    "embedding_size = 256\n",
    "image_feature_size = 2048\n",
    "num_words = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_feature_input = Input(shape=(image_feature_size,),\n",
    "                              name='image_feature_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_transfer_map = Dense(state_size,\n",
    "                             activation='tanh',\n",
    "                             name='decoder_transfer_map')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "report_decoder_input = Input(shape=(max_capt_len, ), name='decoder_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_embedding = Embedding(input_dim=vocab_size,\n",
    "                              output_dim=embedding_size,\n",
    "                              name='decoder_embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_gru1 = GRU(state_size, name='decoder_gru1',\n",
    "                   return_sequences=True)\n",
    "decoder_gru2 = GRU(state_size, name='decoder_gru2',\n",
    "                   return_sequences=True)\n",
    "decoder_gru3 = GRU(state_size, name='decoder_gru3',\n",
    "                   return_sequences=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_dense = Dense(vocab_size,\n",
    "                      activation='linear',\n",
    "                      name='decoder_output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def connect_decoder(transfer_values):\n",
    "    \n",
    "    initial_state = decoder_transfer_map(transfer_values)\n",
    "    \n",
    "    net = report_decoder_input\n",
    "    \n",
    "    net = decoder_embedding(net)\n",
    "    \n",
    "    net = decoder_gru1(net, initial_state=initial_state)\n",
    "    net = decoder_gru2(net, initial_state=initial_state)\n",
    "    net = decoder_gru3(net, initial_state=initial_state)\n",
    "    \n",
    "    net = Flatten()(net)\n",
    "    decoder_output = decoder_dense(net)\n",
    "    \n",
    "    return decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_output = connect_decoder(transfer_values=image_feature_input)\n",
    "\n",
    "decoder_model = Model(inputs=[image_feature_input, report_decoder_input],\n",
    "                      outputs=[decoder_output])\n",
    "decoder_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Old Model\n",
    "\"\"\"def create_model(return_model = False):\n",
    "        \n",
    "        image_decod_input = Input(shape=(2048,))\n",
    "        image_decod = Dense(embedding_dim, input_dim=2048, activation='relu')(image_decod_input)\n",
    "        image_decod = RepeatVector(max_capt_len)(image_decod)\n",
    "        \n",
    "        \n",
    "        capt_decod_input = Input(shape=(max_capt_len,))\n",
    "        capt_decod = Embedding(vocab_size, 256, input_length=max_capt_len)(capt_decod_input)\n",
    "        capt_decod = LSTM(256,return_sequences=True)(capt_decod)\n",
    "        capt_decod = TimeDistributed(Dense(embedding_dim))(capt_decod)\n",
    "        \n",
    "        model = K.layers.concatenate([image_decod, capt_decod])\n",
    "        model = LSTM(1000,return_sequences=False)(model)\n",
    "        model = Dense(vocab_size)(model)\n",
    "        prediction = Activation('softmax')(model)\n",
    "        \n",
    "        model = Model(inputs=[image_decod_input, capt_decod_input], outputs=prediction)\n",
    "\n",
    "        if(return_model==True):\n",
    "            return model\n",
    "\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "        return model\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_a_batch(batch_size = 32):\n",
    "        partial_caps = []\n",
    "        next_words = []\n",
    "        images = []\n",
    "        gen_count = 0\n",
    "        df = pd.read_csv('train_caption_final.csv', delimiter=',')\n",
    "        nb_samples = df.shape[0]\n",
    "        iter = df.iterrows()\n",
    "        caps = []\n",
    "        imgs = []\n",
    "        for i in range(nb_samples):\n",
    "            x = iter.__next__()\n",
    "            caps.append(x[1][1])\n",
    "            imgs.append(x[1][0])\n",
    "\n",
    "\n",
    "        total_count = 0\n",
    "        while True:\n",
    "            image_counter = -1\n",
    "            for text in caps:\n",
    "                image_counter+=1\n",
    "                current_image = encoded_images[imgs[image_counter]][0]\n",
    "                #print(current_image.shape)\n",
    "                for i in range(len(text.split())-1):\n",
    "                    total_count+=1\n",
    "                    partial = [word_to_index[txt] for txt in text.split()[:i+1]]\n",
    "                    partial_caps.append(partial)\n",
    "                    next = np.zeros(vocab_size)\n",
    "                    next[word_to_index[text.split()[i+1]]] = 1\n",
    "                    next_words.append(next)\n",
    "                    images.append(current_image)\n",
    "                    #print(images[0].shape)\n",
    "\n",
    "                    if total_count>=batch_size:\n",
    "                        next_words = np.asarray(next_words)\n",
    "                        images = np.asarray(images)\n",
    "                        partial_caps = sequence.pad_sequences(partial_caps, maxlen=max_capt_len, padding='post')\n",
    "                        total_count = 0\n",
    "                        gen_count+=1\n",
    "                        if gen_count%10 == 0:\n",
    "                            print(\"batch count: \"+str(gen_count))\n",
    "                        yield [[images, partial_caps], next_words]\n",
    "                        partial_caps = []\n",
    "                        next_words = []\n",
    "                        images = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "batch count: 10\n"
     ]
    }
   ],
   "source": [
    "#image_caption_model = create_model()\n",
    "file_name = 'saved_weights_epoch_{epoch:02d}.hdf5'\n",
    "checkpoint = ModelCheckpoint(file_name, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "checkpoints_list = [checkpoint]\n",
    "decoder_model.fit_generator(generate_a_batch(batch_size=batch_size), steps_per_epoch=total_samples/batch_size, epochs=epochs, verbose=2, callbacks=checkpoints_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
